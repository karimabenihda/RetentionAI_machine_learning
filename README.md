# Machine Learning â€“ RetentionAI

## ğŸ¯ Objectif

Construire un **modÃ¨le de Machine Learning supervisÃ©** capable de prÃ©dire le risque de dÃ©part (attrition) dâ€™un employÃ© Ã  partir de donnÃ©es RH structurÃ©es.

Ce modÃ¨le est ensuite exposÃ© via une API FastAPI et utilisÃ© en production.

---

## ğŸ“ Structure du module

```
machine_learning_RetentionAI/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ eda.ipynb
â”‚   â””â”€â”€ rf_attrition.pkl
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š DonnÃ©es & ProblÃ©matique

* DonnÃ©es RH internes (Ã¢ge, salaire, rÃ´le, satisfaction, anciennetÃ©, etc.)
* Variable cible : **Attrition** (0 = reste, 1 = quitte)
* ProblÃ¨me : **dÃ©sÃ©quilibre des classes** (peu de dÃ©parts)

---

## ğŸ” Analyse Exploratoire (EDA)

Notebook : `eda.ipynb`

### Ã‰tapes rÃ©alisÃ©es

* Suppression des variables inutiles
* Analyse de la distribution de la cible
* Visualisations avec **Seaborn**
* Ã‰tude de corrÃ©lation avec la cible
* Analyse des relations mÃ©tier (anciennetÃ©, salaire, satisfaction)

---

## âš™ï¸ PrÃ©processing

* Transformation de la cible (binaire)
* Encodage des variables catÃ©gorielles â†’ `OneHotEncoder`
* Normalisation / standardisation
* SÃ©paration : `train_test_split`

---

## ğŸ¤– ModÃ¨les testÃ©s

* RÃ©gression Logistique
* Support Vector Classifier (SVC)
* Random Forest Classifier

### DÃ©sÃ©quilibre des classes

* Application de **SMOTE** pour amÃ©liorer le rappel sur la classe minoritaire

---

## ğŸ“ˆ Ã‰valuation

MÃ©triques utilisÃ©es :

* Matrice de confusion
* Recall (classe Attrition = 1)
* F1-score
* Courbe ROC
* Rapport de classification

---

## ğŸ† RÃ©sultats comparatifs

| ModÃ¨le                | Avant SMOTE             | AprÃ¨s SMOTE                             |
| --------------------- | ----------------------- | --------------------------------------- |
| SVC                   | Recall: 0.50 â€“ F1: 0.46 | Recall_macro: 0.69 â€“ F1_macro: 0.63     |
| RÃ©gression Logistique | Recall: 0.55 â€“ F1: 0.47 | Recall_macro: 0.65 â€“ F1_macro: 0.54     |
| **Random Forest**     | Recall: 0.39 â€“ F1: 0.43 | **Recall_macro: 0.67 â€“ F1_macro: 0.70** |

---

## âœ… Pourquoi Random Forest ?

* Meilleur compromis **prÃ©cision / rappel** aprÃ¨s SMOTE
* Bonne capacitÃ© Ã  gÃ©rer les relations non linÃ©aires
* Robuste au bruit
* Importance des variables interprÃ©table
* AdaptÃ© Ã  un contexte mÃ©tier RH

â¡ï¸ **Choisi comme modÃ¨le final**

---

## ğŸ’¾ Sauvegarde du modÃ¨le

* ModÃ¨le final sauvegardÃ© avec `joblib`
* Fichier : `rf_attrition.pkl`
* ChargÃ© dynamiquement dans lâ€™API backend

---

## ğŸ”Œ IntÃ©gration Backend

* Chargement via `model_loader.py`
* Endpoint `/predict`
* Retour :

  * `prediction` (0 / 1)
  * `probability`

---

## ğŸš€ AmÃ©liorations futures

* Feature importance SHAP
* Monitoring du modÃ¨le (MLflow)
* RÃ©entraÃ®nement automatique
* DÃ©tection de dÃ©rive des donnÃ©es

---

## ğŸ§  Conclusion

Ce module ML constitue le **cÅ“ur dÃ©cisionnel** de RetentionAI et fournit une prÃ©diction fiable, explicable et exploitable par les Ã©quipes RH.
